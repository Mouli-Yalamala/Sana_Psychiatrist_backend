# ğŸ§ Sana â€” Multimodal Mental Health Assistant (Text + Voice)

**Sana** is a compassionate, multimodal mental-health assistant powered by **Groq LLM**, **FastAPI**, **Speech Recognition**, and **Text-to-Speech**.  
It supports:

- ğŸ—£ï¸ **Voice input â†’ Text** (Speech-to-Text)  
- ğŸ”Š **Text â†’ Voice output** (Text-to-Speech)  
- ğŸ’¬ **Emotionally supportive conversations**  
- ğŸŒ **Multi-language support**  
- ğŸ”’ **Local chat history storage**  
- âš¡ **Fast responses using Groq LLaMA 3.1 8B-Instant**

This project aims to create a warm, empathetic conversational experience for users who want emotional support or someone to talk to.

---

## ğŸ“ Project Structure

```
Psychartist/
â”‚
â”œâ”€â”€ backend.py             # Core FastAPI backend with STT + TTS + Chat
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ chat_history.json      # Local chat memory (auto-generated)
â”œâ”€â”€ README.md              # Documentation
â”‚
â””â”€â”€ __pycache__/           # Python cache (ignored)
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/Psychartist.git
cd Psychartist
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set up environment variables

Create a `.env` file:

```
GROQ_API_KEY=your_groq_api_key_here
```

---

## ğŸš€ Running the Backend Server

Start the FastAPI server:

```bash
python backend.py
```

This launches the API, which includes:

- `/chat` â†’ Text-based conversation endpoint  
- `/transcribe_audio` â†’ Speech-to-text endpoint  

You can connect this to a **frontend**, **mobile app**, or **desktop UI** easily.

---

## ğŸ§  AI Capabilities

### âœ” Empathetic Conversations  
The assistant follows a detailed **system prompt** that ensures:

- warm, compassionate responses  
- open-ended emotional questions  
- no medical diagnosis  
- supportive tone  
- multi-language replies  

### âœ” Speech-to-Text (Audio â†’ Text)  
Powered by:

- **SpeechRecognition**
- **Google Speech API**
- **Pydub**

```bash
POST /transcribe_audio
```

### âœ” Text-to-Speech (Text â†’ Audio Base64)  
Generated using:

- **pyttsx3**
- Temporary WAV files
- Base64 encoding for easy frontend playback

### âœ” Chat Completions (Groq API)  
Ultra-fast responses using:

- **LLaMA-3.1-8B-Instant**

---

## ğŸ§ª Sample Chat Request

```python
from model import RAG

rag = RAG()
response = rag.ask("I've been feeling sad lately...")
print(response)
```

---

## ğŸ“¡ API Endpoints

### ğŸ”µ **POST /chat**
Send a message â†’ get empathetic response + audio TTS

**Form Fields:**
- `message`: user text  
- `language`: response language (default: english)

**Response:**
```json
{
  "reply": "I'm really sorry you're feeling this way...",
  "audio_base64": "UklGRiQAAABXQVZFZm10IBAAAAABAAEA..."
}
```

---

### ğŸ”µ **POST /transcribe_audio**
Upload an audio file â†’ get transcript

**Form Fields:**
- `language`: (optional)
- `audio_file`: WAV/MP3/etc.

---

## ğŸ’¾ Chat History

Conversations are stored locally in:

```
chat_history.json
```

This ensures:

- session memory  
- personalized replies  
- continuity between interactions  

---

## ğŸ›¡ï¸ Error Handling

Global exception handler ensures:

- readable error logs  
- 500 Internal Server Error fallback  
- safe user experience  

---

## ğŸ›  Technologies Used

- **FastAPI**
- **Groq LLaMA-3.1-8B-Instant**
- **SpeechRecognition**
- **Pydub**
- **pyttsx3 TTS**
- **Python asyncio + ThreadPoolExecutor**
- **CORS Middleware for frontend integration**

---

## ğŸ“Œ Future Improvements

- Add emotional sentiment detection  
- Add memory summarization  
- Add WebSockets for real-time chat  
- Add user-specific profiles  
- Deploy on Cloud (Railway / Render / HuggingFace Spaces)  
- Add proper UI (React / Flutter / Streamlit)

---

## âœ¨ Author

**Mouli Yalamala**  
AI/ML Developer | Speech + NLP | Agentic Systems  
GitHub: https://github.com/Mouli-Yalamala  

---

## â­ Support

If this project helped or inspired you, please consider **starring â­ the repository**!

